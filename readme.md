# ðŸ¤– AI RAG Agent using LangGraph, Gemini 2.0, and ChromaDB

This project implements a Retrieval-Augmented Generation (RAG) system using **LangGraph**, **Gemini 2.0 Flash**, and **ChromaDB**. The agent answers questions based on a small local knowledge base of `.txt` files and includes evaluation components such as **LLM-as-a-Judge** and **ROUGE scoring** to assess answer quality.

---

## ðŸš€ Features

- **LangGraph Workflow:**Plan â†’ Retrieve â†’ Answer â†’ Reflect
- **Gemini 2.0 Flash** for answer generation
- **ChromaDB** vector store for fast semantic retrieval
- **MiniLM Embeddings** for lightweight embedding generation
- **Evaluation Tools:**
  - LLM-as-a-Judge (Gemini)
  - ROUGE-1, ROUGE-2, ROUGE-L
- **Streamlit UI** included
- Clean, modular, interview-friendly structure

---

## ðŸ§  How the Agent Works

The agent follows a structured 4-node workflow orchestrated by **LangGraph**:

### 1. **Plan Node**

Determines whether retrieval is needed based on question keywords.

### 2. **Retrieve Node**

Fetches the most relevant text chunk from ChromaDB using MiniLM embeddings.

### 3. **Answer Node**

Uses Gemini 2.0 Flash to generate a grounded response using ONLY the retrieved context.

### 4. **Reflect Node**

Rates the answer (0â€“10) and provides a one-sentence explanation of its quality.

This ensures controlled generation, reduced hallucinations, and highly interpretable execution flow.

---

## ðŸ› ï¸ Setup Instructions

### 1. Install Dependencies

```bash
pip install -r requirements.txt
```

### 2. Add API Keys (Important)

Set your Gemini API key:

```bash
export GEMINI_API_KEY="your_key_here"
```

(Optional) LangSmith:

```bash
export LANGSMITH_API_KEY="your_key_here"
```

### 3. Run Streamlit App

```bash
streamlit run app.py
```

---

## ðŸ“ Folder Structure

```
project/
â”‚â”€â”€ rag_agent.py               # Main RAG pipeline
â”‚â”€â”€ evaluation.py              # LLM-as-Judge + ROUGE scoring
â”‚â”€â”€ app.py                     # Streamlit UI
â”‚â”€â”€ requirements.txt         
â”‚â”€â”€ README.md                
â”‚â”€â”€ data/                      # Knowledge base
â”‚     â”œâ”€â”€ ai.txt
â”‚     â”œâ”€â”€ data_science.txt
â”‚     â”œâ”€â”€ deep_learning.txt
â”‚     â”œâ”€â”€ machine_learning.txt
â”‚     â””â”€â”€ python_programming.txt
```

---

## ðŸ“Š Architecture Diagram (ASCII)

```
                 â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                 â”‚   User QnA   â”‚
                 â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
                         â”‚
                 â”Œâ”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”
                 â”‚     PLAN      â”‚
                 â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
                 retrieve?â”‚yes
                         â”‚
                 â”Œâ”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”
                 â”‚   RETRIEVE    â”‚
                 â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚context
                 â”Œâ”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”
                 â”‚    ANSWER     â”‚
                 â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚
                 â”Œâ”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”
                 â”‚    REFLECT    â”‚
                 â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚
                 â”Œâ”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€-â”
                 â”‚   Final Outputâ”‚
                 â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ðŸ”µ Architecture Diagram

````markdown
```mermaid
flowchart TD
    A[User Question] --> B[PLAN Node]
    B -->|Retrieval Needed| C[RETRIEVE Node]
    B -->|No Retrieval| D[ANSWER Node]
    C --> D[ANSWER Node]
    D --> E[REFLECT Node]
    E --> F[Final Answer + Reflection]
```
````
